<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DREAM: Visual Decoding from Reversing Human Visual System.">
  <meta name="keywords" content="DREAM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DREAM: Visual Decoding from Reversing Human Visual System</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
          <!-- DREAM: Visual Decoding from Reversing Human Visual System -->
          <span style="color: #cd7ca0;">D</span><span style="color: #7ca0cd;">RE</span><span style="color: #7ccda9;">A</span><span style="color: #cda97c;">M</span>: Visual <span style="color: #cd7ca0;">D</span>ecoding from <span style="color: #7ca0cd;">RE</span>versing Hum<span style="color: #7ccda9;">A</span>n Visual Syste<span style="color: #cda97c;">M</span>
          </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href='https://weihaox.github.io/'>Weihao Xia</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href='https://team.inria.fr/rits/membres/raoul-de-charette/'>Raoul de Charette</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href='https://www.cl.cam.ac.uk/~aco41/'>Cengiz Ã–ztireli</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href='http://www.homepages.ucl.ac.uk/~ucakjxu/'>Jing-Hao Xue</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University College London</span>,
            <span class="author-block"><sup>2</sup>Inria</span>,
            <span class="author-block"><sup>3</sup>University of Cambridge</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Paper Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.02265"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- PDF Link. -->
<!--               <span class="link-block">
                <a href="https://weihaox.github.io/DREAM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=cUdkeigISOo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/weihaox/DREAM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <!-- <img src="./images/teaser_cycle.png"> -->
        <img src="./images/recon_comparison.png">
      <h2 class="subtitle has-text-centered">
        <!-- DREAM is a Visual Decoding method from REversing HumAn Visual SysteM. -->
        <span style="color: #cd7ca0;">D</span><span style="color: #7ca0cd;">RE</span><span style="color: #7ccda9;">A</span><span style="color: #cda97c;">M</span> is a visual <span style="color: #cd7ca0;">D</span>ecoding method from <span style="color: #7ca0cd;">RE</span>versing Hum<span style="color: #7ccda9;">A</span>n Visual Syste<span style="color: #cda97c;">M</span>.
      </h2>
    </div>
  </div>
</section>

<!-- Teaser. -->
<div style="text-align:center;">
    <img src="./images/teaser_cycle.png" alt="teaser" style="width:30%; height:auto;">
</div>
<!--/ Teaser. -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            <!-- We present DREAM, a Visual Decoding method from REversing HumAn Visual SysteM. -->       
            We present <span style="color: #cd7ca0;">D</span><span style="color: #7ca0cd;">RE</span><span style="color: #7ccda9;">A</span><span style="color: #cda97c;">M</span>, a visual <span style="color: #cd7ca0;">D</span>ecoding method from <span style="color: #7ca0cd;">RE</span>versing Hum<span style="color: #7ccda9;">A</span>n Visual Syste<span style="color: #cda97c;">M</span>.
          </p>
          <p>
            <span style="color: #cd7ca0;">D</span><span style="color: #7ca0cd;">RE</span><span style="color: #7ccda9;">A</span><span style="color: #cda97c;">M</span> is an fMRI-to-image method for reconstructing viewed images from brain activities, grounded on fundamental knowledge of the <a href="https://en.wikipedia.org/wiki/Visual_system">human visual system (HVS)</a>. We craft reverse pathways that emulate the hierarchical and parallel nature of how humans perceive the visual world. These tailored pathways are specialized to decipher semantics, color, and depth cues from fMRI data, mirroring the forward pathways from visual stimuli to fMRI recordings.
          </p>
          <p> 
            Two components mimic the inverse processes within the HVS: the Reverse Visual Association Cortex (R-VAC) which reverses pathways of this brain region, extracting semantics from fMRI data; the Reverse Parallel PKM (R-PKM) component simultaneously predicting color and depth from fMRI. The final images are reconstructed by the Color Adapter (C-A) and the Depth Adapter (D-A) in T2I-Adapter in conjunction with SD from deciphered semantics, color, and depth cues.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Framework. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Framework Overview</h2>
        <div class="content has-text-justified">
          <img src="./images/method_overview.png">
          <p>
            Grounding on the Human Visual System (HVS), we devise reverse pathways aimed at deciphering semantics, depth, and color cues from fMRI to guide image reconstruction. 
          </p>
          <p>
            <b>(Left)</b> Schematic view of HVS. When perceiving visual stimuli, connections from the retina to the brain can be separated into two parallel pathways. The Parvocellular Pathway originates from midget cells in the retina and is responsible for transmitting color information, while the Magnocellular Pathway starts with parasol cells and is specialized in detecting depth and motion. The conveyed information is channeled into the visual cortex for undertaking intricate processing of high-level semantics from the visual image. 
          </p>
          <p> 
            <b>(Right)</b> <span style="color: #cd7ca0;">D</span><span style="color: #7ca0cd;">RE</span><span style="color: #7ccda9;">A</span><span style="color: #cda97c;">M</span> mimics the corresponding inverse processes within the HVS: the Reverse VAC replicates the opposite operations of this brain region, analogously extracting semantics as a form of CLIP embedding from fMRI; and the Reverse PKM maps fMRI to color and depth in the form of spatial palettes and depth maps to facilitate subsequent processing by the Color Adapter (C-A) and the Depth Adapter (D-A) in T2I-Adapter in conjunction with SD for image reconstruction from deciphered semantics, color, and depth cues.
          </p>
        </div>
      </div>
    </div>
    <!--/ Framework. -->

    <!-- Visual Decoding with DREAM. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          Visual Decoding with <span style="color: #cd7ca0;">D</span><span style="color: #7ca0cd;">RE</span><span style="color: #7ccda9;">A</span><span style="color: #cda97c;">M</span>
        </h2>
        <div class="content has-text-justified">
                    <img src="./images/color_significance.png">
          <p>
            Our study shows that current visual decoding methods often underscored and unnoticed color, which in fact plays an indispensable role. The  images generated without color guidance, while accurate in semantics, deviate in color from the original visual stimuli. This phenomenon arises due to the absence of proper color guidance and address the significance role of color in visual decoding.
          </p>
                    <img src="./images/supmat_more_reconstruction_result.png">
          <p>
            We show reconstruction for subject 1 from the NSD dataset. Our approach extracts essential cues from fMRI recordings, leading to enhanced consistency in appearance, structure, and semantics when compared to the viewed visual stimuli. The results are randomly selected. The illustrated depth, color, and final images demonstrate that the deciphered and represented color and depth cues help to boost the performance of visual decoding.
          </p>
          <p>
            While accurate depth is beneficial for image reconstruction, faithfully recovering the original depth from fMRI is nearly impossible due to the information loss in capturing the brain activities. Still, coarse depth is sufficient in most cases to guide the scene structure and object position such as determining the location of an airplane or the orientation of a bird standing on a branch. 
            Despite not precisely preserving the local color, the estimated color palettes provide a reliable constraint and guidance on the overall scene appearance.
          </p>
                    <img src="./images/supmat_other_subject.png">
          <p>
          Subject-Specific Results. We visualize subject-specific outputs of <span style="color: #cd7ca0;">D</span><span style="color: #7ca0cd;">RE</span><span style="color: #7ccda9;">A</span><span style="color: #cda97c;">M</span> on the NSD dataset. For each subject, the model is retrained because the brain activity varies across subjects. Overall, it consistently reconstructs the test image for all subjects while we note that some reconstruction inaccuracies are shared across subjects.
          </p>
        </div>
      </div>
    </div>
    <!--/ Visual Decoding with DREAM. -->
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">Citation</h2>
    <pre><code>@inproceedings{xia2023dream,
  author    = {Xia, Weihao and de Charette, Raoul and Ã–ztireli, Cengiz and Xue, Jing-Hao},
  title     = {DREAM: Visual Decoding from Reversing Human Visual System},
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year      = {2024},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
        <div class="content">
          <p>
            Acknowledgements: The website template was borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
</footer>

</body>
</html>
